# -----------------------------
# Docker Compose / Runtime
# -----------------------------
COMPOSE_PROJECT_NAME=code-compass

# -----------------------------
# Escopo global do MCP
# -----------------------------
ALLOW_GLOBAL_SCOPE=false

# -----------------------------
# Qdrant (infra local)
# -----------------------------
QDRANT_IMAGE=qdrant/qdrant:latest
QDRANT_HTTP_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_STORAGE_PATH=./qdrant_data
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_BASE=compass_manutic_nomic_embed
QDRANT_DISTANCE=COSINE
QDRANT_UPSERT_BATCH=64
QDRANT_URL_DOCKER=http://qdrant:6333
RRF_K=60
RRF_DIVERSITY_FLOOR=1

# -----------------------------
# Indexer (apps/indexer)
# -----------------------------
INDEXER_DIR=apps/indexer
INDEXER_PYTHON=python3
INDEXER_RUN_MODULE=indexer
INDEXER_DOCKER_PROFILE=indexer
INDEXER_DOCKER_IMAGE=python:3.11-slim

# -----------------------------
# Repositório e chunking
# -----------------------------
REPO_ROOT_DOCKER=/workspace
REPO_ROOT=/abs/path/para/repositorio
REPO_ALLOWLIST=src,packages,apps,docs
REPO_BLOCKLIST=node_modules,dist,build,.next,.git,coverage
SCAN_IGNORE_DIRS=.git,node_modules,dist,build,.next,.qdrant_storage,coverage
SCAN_ALLOW_EXTS=.ts,.tsx,.js,.jsx,.py,.md,.json,.yaml,.yml
SCAN_IGNORE_PATTERNS=
CHUNK_LINES=120
CHUNK_OVERLAP_LINES=20
INDEX_MIN_FILE_COVERAGE=0.95
SEARCH_SNIPPET_MAX_CHARS=300
DOC_EXTENSIONS=.md,.mdx,.rst,.adoc,.txt
DOC_PATH_HINTS=/docs/,/documentation/,/adr,/wiki/,/changelog,/contributing,/license,/readme
EXCLUDED_CONTEXT_PATH_PARTS=/.venv/,/venv/,/__pycache__/,/.pytest_cache/,/.mypy_cache/,/.ruff_cache/
CONTENT_TYPES=code,docs

# -----------------------------
# Embeddings (ask_code)
# -----------------------------
EMBEDDING_PROVIDER_CODE=ollama
EMBEDDING_PROVIDER_DOCS=ollama
EMBEDDING_PROVIDER_CODE_API_URL=http://localhost:11434
EMBEDDING_PROVIDER_DOCS_API_URL=http://localhost:11434
EMBEDDING_PROVIDER_CODE_API_KEY=
EMBEDDING_PROVIDER_DOCS_API_KEY=
EMBEDDING_MODEL_CODE=manutic/nomic-embed-code
EMBEDDING_MODEL_DOCS=bge-m3
EMBEDDING_BATCH_SIZE=16
EMBEDDING_MAX_RETRIES=5
EMBEDDING_BACKOFF_BASE_MS=500
EMBEDDING_TIMEOUT_SECONDS=120

# Alternativo: OpenAI
# EMBEDDING_PROVIDER_CODE=openai
# EMBEDDING_PROVIDER_DOCS=openai
# EMBEDDING_MODEL_CODE=text-embedding-3-large
# EMBEDDING_MODEL_DOCS=text-embedding-3-large
# OPENAI_API_KEY=YOUR_KEY

# -----------------------------
# LLM (chat final do ask_code)
# Provider suportado: ollama (default), deepseek, openai-compatible
# -----------------------------
LLM_MODEL_PROVIDER=ollama
LLM_MODEL=gpt-oss:latest
LLM_MODEL_API_URL=http://localhost:11434
LLM_MODEL_API_KEY=

# Compatibilidade legada (opcional)
# LLM_PROVIDER=
# LLM_API_BASE_URL=
# LLM_API_KEY=

# -----------------------------
# MCP server (apps/mcp-server)
# -----------------------------
MCP_SERVER_NAME=code-compass
MCP_SERVER_PORT=3333
CODEBASE_ROOT=/abs/path/para/code-base

# -----------------------------
# ACP Agent
# -----------------------------
ACP_CONTENT_TYPE=all
ACP_STRICT=false

# -----------------------------
# Segurança / governança
# -----------------------------
READ_ONLY=true
AUDIT_LOG_ENABLED=true
PATH_TRAVERSAL_GUARD=true
